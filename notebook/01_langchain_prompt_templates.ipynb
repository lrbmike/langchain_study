{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 提示词工程"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c94d8b0dcd7c8357"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## PromptTemplate\n",
    "使用 PromptTemplate 为字符串提示创建模板，可通过 '{}' 占位符，替换模板的内容。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f2088ed8c5606982"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell me a funny joke about chickens.\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    \"Tell me a {adjective} joke about {content}.\"\n",
    ")\n",
    "\n",
    "print(\n",
    "    prompt_template.format(adjective=\"funny\", content=\"chickens\")\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:38:04.606451300Z",
     "start_time": "2024-01-27T06:38:04.559156800Z"
    }
   },
   "id": "1b0e5b3cb6344438"
  },
  {
   "cell_type": "markdown",
   "source": [
    "模板支持任意数量的变量，包括无变量。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a52bbbae76bd6ab0"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "'Tell me a joke'"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Tell me a joke\")\n",
    "\n",
    "print(\n",
    "    prompt_template.format()\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:39:16.439361Z",
     "start_time": "2024-01-27T06:39:16.413712800Z"
    }
   },
   "id": "d3a2f53475904f33"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们通常不会事先知道用户的提示是什么，所以我们实际上想添加它。因此，我们不是直接编写提示，而是使用单个输入变量查询创建一个 PromptTemplate。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2d7ea58025f210f3"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer the question based on the context below. If the\n",
      "question cannot be answered using the information provided answer\n",
      "with \"I don't know\".\n",
      "\n",
      "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
      "Their superior performance over smaller models has made them incredibly\n",
      "useful for developers building NLP enabled applications. These models\n",
      "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
      "using the `openai` library, and via Cohere using the `cohere` library.\n",
      "\n",
      "Question: Which libraries and model providers offer LLMs?\n",
      "\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based on the context below. If the\n",
    "question cannot be answered using the information provided answer\n",
    "with \"I don't know\".\n",
    "\n",
    "Context: Large Language Models (LLMs) are the latest models used in NLP.\n",
    "Their superior performance over smaller models has made them incredibly\n",
    "useful for developers building NLP enabled applications. These models\n",
    "can be accessed via Hugging Face's `transformers` library, via OpenAI\n",
    "using the `openai` library, and via Cohere using the `cohere` library.\n",
    "\n",
    "Question: {query}\n",
    "\n",
    "Answer: \"\"\"\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"query\"],\n",
    "    template=template\n",
    ")\n",
    "\n",
    "print(\n",
    "    prompt_template.format(\n",
    "        query=\"Which libraries and model providers offer LLMs?\"\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T07:08:56.904394700Z",
     "start_time": "2024-01-27T07:08:56.887194500Z"
    }
   },
   "id": "e0caf5fe29cd81f1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## ChatPromptTemplate\n",
    "聊天模型的提示是一个聊天消息列表，每条聊天消息都与内容以及称为角色的附加参数相关联。例如会有AI助力、人类或者系统角色相关联。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf6658971d0958fd"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name?')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        (\"human\", \"Hello, how are you doing?\"),\n",
    "        (\"ai\", \"I'm doing well, thanks!\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "print(messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:43:50.530391500Z",
     "start_time": "2024-01-27T06:43:50.510810700Z"
    }
   },
   "id": "3604c830efcb628"
  },
  {
   "cell_type": "markdown",
   "source": [
    "也可以使用不同的角色提示模板，分别创建不同的角色消息。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "411d843546df3f19"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='You are a helpful AI bot. Your name is Bob.'), HumanMessage(content='Hello, how are you doing?'), AIMessage(content=\"I'm doing well, thanks!\"), HumanMessage(content='What is your name?')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, SystemMessagePromptTemplate, AIMessagePromptTemplate\n",
    "\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        SystemMessagePromptTemplate.from_template(\"You are a helpful AI bot. Your name is {name}.\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"Hello, how are you doing?\"),\n",
    "        AIMessagePromptTemplate.from_template(\"I'm doing well, thanks!\"),\n",
    "        HumanMessagePromptTemplate.from_template(\"{user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "messages = chat_template.format_messages(name=\"Bob\", user_input=\"What is your name?\")\n",
    "\n",
    "print(messages)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T06:50:58.874588900Z",
     "start_time": "2024-01-27T06:50:58.857161200Z"
    }
   },
   "id": "cabc89c1e973d16f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们尝试使用 openai 模型来构建使用 prompt 模版输出内容"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3a614488c2456f2a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "配置 openai key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3b3aa5208fc547a3"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%env OPENAI_API_KEY=you-api-key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6736285537cc0f51"
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果无法访问 openai api，可以配置 base url"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b9867ced417305f5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%env OPENAI_API_BASE=you-base-url"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "faec59d889f3684e"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "'Why did the ice cream go to the party? Because it was feeling a little \"sundae\"!'"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "import os\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", openai_api_key=os.getenv(\"OPENAI_API_KEY\"), openai_api_base=os.getenv(\"OPENAI_API_BASE\"))\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "chain.invoke({\"topic\": \"ice cream\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T04:22:47.004979100Z",
     "start_time": "2024-01-27T04:22:43.781693200Z"
    }
   },
   "id": "d1d6a096c0bb2c3e"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "36e47ba20563e4d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
