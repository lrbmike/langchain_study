{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# chain 链"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0a8c83aefbc2fdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "链是LangChain的核心。它们是一系列组件，按特定顺序执行。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3dbfacc0c302a6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一个最简单的例子: prompt + model + output parser\n",
    "目前官网推荐使用 LCEL 方式来构建 Chain，即 LangChain Expression Language。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77adbd522a0be479"
  },
  {
   "cell_type": "markdown",
   "source": [
    "需要配置 openai key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e274effd3d980270"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=you-api-key\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=you-api-key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T09:06:20.625969500Z",
     "start_time": "2024-01-27T09:06:20.604265600Z"
    }
   },
   "id": "6fcb8ad7bfd51123"
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果无法访问 openai api，可以配置 base url"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba5ac573b470db0f"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_BASE=you-base-url\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_BASE=you-base-url"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T09:06:22.844195Z",
     "start_time": "2024-01-27T09:06:22.822111900Z"
    }
   },
   "id": "398f1fe52b06cfa4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以额外定义一个函数去计算每次使用的 tokens 数量，这样我们就可以方便地查看每次调用 api 所消耗的 tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c620556e3663d413"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def chain_invoke_tokens(chain, prompt):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.invoke(prompt)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens\\n')\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T08:13:29.380482200Z",
     "start_time": "2024-01-27T08:13:29.360682600Z"
    }
   },
   "id": "42373536c5c70f3e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用聊天模板，gpt3.5 turbo 模型，构建一个简单的 llm 链。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f62a246851ad0ca"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 39 tokens\n",
      "Why did the ice cream go to therapy? \n",
      "\n",
      "Because it had too many toppings and couldn't get its scoop together!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "print(\n",
    "    chain_invoke_tokens(chain, {\"topic\": \"ice cream\"})\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T08:12:01.810297100Z",
     "start_time": "2024-01-27T08:11:58.250852500Z"
    }
   },
   "id": "cbb9f3dad756a8da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了深入了解LangChain应用程序的内部工作，可以使用 set_verbose 和 set_debug 来了解引擎执行的细节。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94a03528aa87cd74"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "set_verbose(True)\n",
    "set_debug(True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T08:51:38.435181066Z",
     "start_time": "2024-03-08T08:51:38.386906887Z"
    }
   },
   "id": "e4813a659852fbc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "加入 PythonREPL 工具，用于数学计算，构建新的链。使用 Google 的 Gemini 模型来演示"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a3406ef555886dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "配置 api_key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec47c3518b5c66e2"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_API_KEY=you-api-key\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_API_KEY=you-api-key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T15:28:54.129562800Z",
     "start_time": "2024-03-18T15:28:54.104889100Z"
    }
   },
   "id": "d074ce7bd38ab58c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果无法访问 api，可以配置 endpoint"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "156c0f3cee345e4b"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_API_ENDPOINT=you-api-endpoint\n"
     ]
    }
   ],
   "source": [
    "%env GOOGLE_API_ENDPOINT=you-api-endpoint"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-18T15:28:56.209155400Z",
     "start_time": "2024-03-18T15:28:56.177357600Z"
    }
   },
   "id": "352f8c4cc53fa506"
  },
  {
   "cell_type": "markdown",
   "source": [
    "引入需要的组件库"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2444e3bddec6f2f0"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import (\n",
    "    ChatPromptTemplate,\n",
    ")\n",
    "from langchain_experimental.utilities import PythonREPL"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T08:48:27.725521287Z",
     "start_time": "2024-03-08T08:48:26.640470445Z"
    }
   },
   "id": "f8755e1678a6f81e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "配置 prompt 模版"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df0ed4295d732693"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "template = \"\"\"Write some python code to solve the user's problem. \n",
    "\n",
    "Return only python code in Markdown format, e.g.:\n",
    "\n",
    "```python\n",
    "....\n",
    "```\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([(\"system\", template), (\"human\", \"{input}\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T08:48:29.970479157Z",
     "start_time": "2024-03-08T08:48:29.948869896Z"
    }
   },
   "id": "ea99664a0b49e3b8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "配置 llm 模型"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "26f0ca4b9a2b728c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0, google_api_key=os.environ['GOOGLE_API_KEY'], transport=\"rest\", client_options={\"api_endpoint\": os.environ['GOOGLE_API_ENDPOINT']}, convert_system_message_to_human=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T08:49:53.292798489Z",
     "start_time": "2024-03-08T08:49:53.244606876Z"
    }
   },
   "id": "eb38db45b622d767"
  },
  {
   "cell_type": "markdown",
   "source": [
    "定义一个格式化的函数，用于提取输出的文本"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6b024af1019921ad"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def _sanitize_output(text: str):\n",
    "    _, after = text.split(\"```python\")\n",
    "    return after.split(\"```\")[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T08:48:36.253384684Z",
     "start_time": "2024-03-08T08:48:36.226700648Z"
    }
   },
   "id": "219fdae50c138a63"
  },
  {
   "cell_type": "markdown",
   "source": [
    "构建 chain 链，并执行"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "707db0efdd5e6258"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"whats 2 plus 2\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"whats 2 plus 2\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [1ms] Exiting Prompt run with output:\n",
      "\u001B[0m[outputs]\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 3:llm:ChatGoogleGenerativeAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Write some python code to solve the user's problem. \\n\\nReturn only python code in Markdown format, e.g.:\\n\\n```python\\n....\\n```\\nHuman: whats 2 plus 2\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised InternalServerError: 500 POST https://ai.goi.oowan.net/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised InternalServerError: 500 POST https://ai.goi.oowan.net/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting.\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised GatewayTimeout: 504 POST https://ai.goi.oowan.net/v1beta/models/gemini-pro:generateContent?%24alt=json%3Benum-encoding%3Dint: An error occurred with your deployment\n",
      "\n",
      "EDGE_FUNCTION_INVOCATION_TIMEOUT\n",
      ".\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 3:llm:ChatGoogleGenerativeAI] [41.91s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"```python\\nprint(2 + 2)\\n```\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"STOP\",\n",
      "          \"safety_ratings\": [\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            },\n",
      "            {\n",
      "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
      "              \"probability\": \"NEGLIGIBLE\",\n",
      "              \"blocked\": false\n",
      "            }\n",
      "          ]\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"```python\\nprint(2 + 2)\\n```\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"prompt_feedback\": {\n",
      "      \"safety_ratings\": [\n",
      "        {\n",
      "          \"category\": 9,\n",
      "          \"probability\": 1,\n",
      "          \"blocked\": false\n",
      "        },\n",
      "        {\n",
      "          \"category\": 8,\n",
      "          \"probability\": 1,\n",
      "          \"blocked\": false\n",
      "        },\n",
      "        {\n",
      "          \"category\": 7,\n",
      "          \"probability\": 1,\n",
      "          \"blocked\": false\n",
      "        },\n",
      "        {\n",
      "          \"category\": 10,\n",
      "          \"probability\": 1,\n",
      "          \"blocked\": false\n",
      "        }\n",
      "      ],\n",
      "      \"block_reason\": 0\n",
      "    }\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] [1ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"```python\\nprint(2 + 2)\\n```\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 5:chain:_sanitize_output] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"```python\\nprint(2 + 2)\\n```\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 5:chain:_sanitize_output] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"\\nprint(2 + 2)\\n\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 6:chain:run] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"input\": \"\\nprint(2 + 2)\\n\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 6:chain:run] [2ms] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"4\\n\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence] [41.93s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"4\\n\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": "'4\\n'"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser() | _sanitize_output | PythonREPL().run\n",
    "\n",
    "chain.invoke({\"input\": \"whats 2 plus 2\"})"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-08T08:52:25.658679309Z",
     "start_time": "2024-03-08T08:51:43.661845955Z"
    }
   },
   "id": "eeea68cdb49b1093"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
