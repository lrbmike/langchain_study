{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "链"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c0a8c83aefbc2fdb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "链是LangChain的核心。它们是一系列组件，按特定顺序执行。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b3dbfacc0c302a6d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一个最简单的例子: prompt + model + output parser\n",
    "目前官网推荐使用 LCEL 方式来构建 Chain，即 LangChain Expression Language。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77adbd522a0be479"
  },
  {
   "cell_type": "markdown",
   "source": [
    "需要配置 openai key"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e274effd3d980270"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_KEY=you-api-key\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_KEY=you-api-key"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T09:06:20.625969500Z",
     "start_time": "2024-01-27T09:06:20.604265600Z"
    }
   },
   "id": "6fcb8ad7bfd51123"
  },
  {
   "cell_type": "markdown",
   "source": [
    "如果无法访问 openai api，可以配置 base url"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ba5ac573b470db0f"
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: OPENAI_API_BASE=you-base-url\n"
     ]
    }
   ],
   "source": [
    "%env OPENAI_API_BASE=you-base-url"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T09:06:22.844195Z",
     "start_time": "2024-01-27T09:06:22.822111900Z"
    }
   },
   "id": "398f1fe52b06cfa4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "我们可以额外定义一个函数去计算每次使用的 tokens 数量，这样我们就可以方便地查看每次调用 api 所消耗的 tokens"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c620556e3663d413"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "def chain_invoke_tokens(chain, prompt):\n",
    "    with get_openai_callback() as cb:\n",
    "        result = chain.invoke(prompt)\n",
    "        print(f'Spent a total of {cb.total_tokens} tokens\\n')\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T08:13:29.380482200Z",
     "start_time": "2024-01-27T08:13:29.360682600Z"
    }
   },
   "id": "42373536c5c70f3e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "使用聊天模板，gpt3.5 turbo 模型，构建一个简单的 llm 链。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f62a246851ad0ca"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spent a total of 39 tokens\n",
      "Why did the ice cream go to therapy? \n",
      "\n",
      "Because it had too many toppings and couldn't get its scoop together!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "\n",
    "print(\n",
    "    chain_invoke_tokens(chain, {\"topic\": \"ice cream\"})\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T08:12:01.810297100Z",
     "start_time": "2024-01-27T08:11:58.250852500Z"
    }
   },
   "id": "cbb9f3dad756a8da"
  },
  {
   "cell_type": "markdown",
   "source": [
    "为了深入了解LangChain应用程序的内部工作，可以使用 set_verbose 和 set_debug 来了解引擎执行的细节。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "94a03528aa87cd74"
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from langchain.globals import set_verbose, set_debug\n",
    "\n",
    "set_verbose(True)\n",
    "set_debug(False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T09:01:32.837116800Z",
     "start_time": "2024-01-27T09:01:32.819587200Z"
    }
   },
   "id": "e4813a659852fbc9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "加入 PythonREPLTool 工具，用于数学计算，构建新的链。"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a3406ef555886dd"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence] Entering Chain run with input:\n",
      "\u001B[0m{\n",
      "  \"query\": \"What is 1 plus 1?\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] Entering Prompt run with input:\n",
      "\u001B[0m{\n",
      "  \"query\": \"What is 1 plus 1?\"\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 2:prompt:ChatPromptTemplate] [0ms] Exiting Prompt run with output:\n",
      "\u001B[0m{\n",
      "  \"lc\": 1,\n",
      "  \"type\": \"constructor\",\n",
      "  \"id\": [\n",
      "    \"langchain\",\n",
      "    \"prompts\",\n",
      "    \"chat\",\n",
      "    \"ChatPromptValue\"\n",
      "  ],\n",
      "  \"kwargs\": {\n",
      "    \"messages\": [\n",
      "      {\n",
      "        \"lc\": 1,\n",
      "        \"type\": \"constructor\",\n",
      "        \"id\": [\n",
      "          \"langchain\",\n",
      "          \"schema\",\n",
      "          \"messages\",\n",
      "          \"HumanMessage\"\n",
      "        ],\n",
      "        \"kwargs\": {\n",
      "          \"content\": \"tell me a result about What is 1 plus 1?\",\n",
      "          \"additional_kwargs\": {}\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[llm/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001B[0m{\n",
      "  \"prompts\": [\n",
      "    \"Human: tell me a result about What is 1 plus 1?\"\n",
      "  ]\n",
      "}\n",
      "\u001B[36;1m\u001B[1;3m[llm/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 3:llm:ChatOpenAI] [1.04s] Exiting LLM run with output:\n",
      "\u001B[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"The result of 1 plus 1 is 2.\",\n",
      "        \"generation_info\": {\n",
      "          \"finish_reason\": \"stop\",\n",
      "          \"logprobs\": null\n",
      "        },\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"AIMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"content\": \"The result of 1 plus 1 is 2.\",\n",
      "            \"additional_kwargs\": {}\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"completion_tokens\": 12,\n",
      "      \"prompt_tokens\": 20,\n",
      "      \"total_tokens\": 32\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo\",\n",
      "    \"system_fingerprint\": null\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[chain/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] Entering Parser run with input:\n",
      "\u001B[0m[inputs]\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 4:parser:StrOutputParser] [0ms] Exiting Parser run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"The result of 1 plus 1 is 2.\"\n",
      "}\n",
      "\u001B[32;1m\u001B[1;3m[tool/start]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 5:tool:Python_REPL] Entering Tool run with input:\n",
      "\u001B[0m\"The result of 1 plus 1 is 2.\"\n",
      "\u001B[36;1m\u001B[1;3m[tool/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence > 5:tool:Python_REPL] [0ms] Exiting Tool run with output:\n",
      "\u001B[0m\"SyntaxError('invalid syntax', ('<string>', 1, 5, 'The result of 1 plus 1 is 2.\\n', 1, 11))\"\n",
      "\u001B[36;1m\u001B[1;3m[chain/end]\u001B[0m \u001B[1m[1:chain:RunnableSequence] [1.04s] Exiting Chain run with output:\n",
      "\u001B[0m{\n",
      "  \"output\": \"SyntaxError('invalid syntax', ('<string>', 1, 5, 'The result of 1 plus 1 is 2.\\\\n', 1, 11))\"\n",
      "}\n",
      "Spent a total of 32 tokens\n",
      "\n",
      "SyntaxError('invalid syntax', ('<string>', 1, 5, 'The result of 1 plus 1 is 2.\\n', 1, 11))\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.callbacks import get_openai_callback\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(\"tell me a result about {query}\")\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "python_repl = PythonREPLTool() \n",
    "\n",
    "chain = prompt | model | output_parser | python_repl\n",
    "\n",
    "print(\n",
    "    chain_invoke_tokens(chain, {\"query\": \"What is 1 plus 1?\"})\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-27T09:01:36.692768900Z",
     "start_time": "2024-01-27T09:01:35.620682700Z"
    }
   },
   "id": "883c2fcbd024dfb1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
